# Influencer AI â€“ Pipeline ibrida OpenRouter + Stable Diffusion

> Toolkit completo per generare, ripulire e addestrare influencer virtuali combinando servizi cloud (OpenRouter) e strumenti locali GPU-ready.

## Indice
- [Panoramica](#panoramica)
- [Architettura del repository](#architettura-del-repository)
- [Prerequisiti](#prerequisiti)
- [Setup rapido](#setup-rapido)
- [Esecuzione della pipeline](#esecuzione-della-pipeline)
  - [1. Preparazione del dataset](#1-preparazione-del-dataset)
  - [2. Storyboard e copy con OpenRouter](#2-storyboard-e-copy-con-openrouter)
  - [3. Generazione batch di immagini](#3-generazione-batch-di-immagini)
  - [4. Controllo qualitÃ ](#4-controllo-qualitÃ )
  - [5. Augment e captioning](#5-augment-e-captioning)
  - [6. Training LoRA](#6-training-lora)
- [Gestione dei checkpoint base](#gestione-dei-checkpoint-base)
- [Control Hub web](#control-hub-web)
- [Struttura delle cartelle dati](#struttura-delle-cartelle-dati)
- [Interfacce alternative](#interfacce-alternative)
- [Test e sviluppo](#test-e-sviluppo)
- [Documentazione aggiuntiva e licenza](#documentazione-aggiuntiva-e-licenza)

## Panoramica
Il progetto **Influencer AI** fornisce un flusso end-to-end per costruire una persona virtuale partendo da un piccolo set di immagini reali, espandere il dataset con generazioni guidate da prompt, verificarne la qualitÃ  e addestrare un LoRA fotorealistico su Stable Diffusion XL. Il repository include:

- stack Docker ottimizzato per GPU NVIDIA con servizi "tools" (Python utility), "comfyui" e "kohya" per l'addestramento;
- script Python per la preparazione del dataset, la generazione tramite OpenRouter e la creazione di caption augmentate;
- una webapp FastAPI per consultare i modelli OpenRouter, lanciare generazioni testo/immagine/video e simulare l'analisi dei profili social;
- automazioni opzionali (GUI desktop e workflow n8n) per orchestrare l'intero ciclo.

## Architettura del repository
- `ai_influencer/docker/docker-compose.yaml` â€“ definisce i container `tools`, `comfyui`, `kohya` e `webapp` con runtime NVIDIA, montando dati, script e modelli sul file system condiviso.
- `ai_influencer/scripts/` â€“ raccolta di utility CLI, fra cui:
  - `prepare_dataset.py` per remove.bg, face crop e normalizzazione immagini;
  - `openrouter_text.py`, `openrouter_images.py` e `openrouter_batch.py` per interrogare le API OpenRouter;
  - `qc_face_sim.py` per filtrare il dataset tramite similaritÃ  facciale e nitidezza;
  - `augment_and_caption.py` per augment e generazione caption coerenti con i metadati;
  - `train_lora.sh` per avviare `sd-scripts` all'interno del container `kohya`.
- `ai_influencer/webapp/` â€“ applicazione FastAPI + frontend vanilla JS che espone endpoint `/api/models`, `/api/generate/*` e `/api/influencer` per pilotare i servizi OpenRouter e raccogliere insight.
- `ai_influencer/scripts/gui_app.py` â€“ interfaccia Tkinter che incapsula i principali step della pipeline CLI.
- `ai_influencer/n8n/flow.json` â€“ workflow n8n che esegue gli script chiave via webhook Docker.
- `tests/` â€“ suite Pytest che copre l'SDK OpenRouter asincrono e gli endpoint principali della webapp.

## Prerequisiti
- **Hardware**: GPU NVIDIA compatibile con CUDA, preferibilmente >= 12 GB VRAM.
- **Software**: Docker Desktop (o Docker Engine) con supporto GPU attivo, Docker Compose v2, Git.
- **Account/Asset**:
  - chiave API OpenRouter (`OPENROUTER_API_KEY`), opzionalmente endpoint personalizzato (`OPENROUTER_BASE_URL`);
  - accesso a Hugging Face (token opzionale) per scaricare automaticamente il modello base SDXL al primo avvio.
- **Storage**: almeno 40â€¯GB liberi per dataset, modelli e checkpoint LoRA.

## Setup rapido
1. Clona il repository e posizionati nella root del progetto:
   ```bash
   git clone https://github.com/<org>/InfluencerAi.git
   cd InfluencerAi
   ```
2. Esporta la chiave OpenRouter nel terminale corrente (o aggiungila a un file `.env` richiamato da Docker Compose):
   ```bash
   export OPENROUTER_API_KEY="sk-or-..."
   ```
3. Avvia lo stack GPU (al primo avvio scarica automaticamente ~6.5â€¯GiB di pesi SDXL in `ai_influencer/models/base/`):
   ```bash
   docker compose -f ai_influencer/docker/docker-compose.yaml up -d
   ```
   I container principali saranno:
   - `ai_influencer_tools` (utility Python + CLI pipeline)
   - `comfyui_local` (interfaccia ComfyUI su http://localhost:8188)
   - `kohya_local` (ambiente kohya_ss per LoRA)
   - `ai_influencer_webapp` (Control Hub su http://localhost:8000)

## Esecuzione della pipeline
Esegui i comandi nel container `ai_influencer_tools` salvo diversa indicazione:
```bash
docker exec -it ai_influencer_tools bash
```

### 1. Preparazione del dataset
Raccogli almeno due immagini del soggetto in `ai_influencer/data/input_raw/`, quindi lancia:
```bash
python3 scripts/prepare_dataset.py \
  --in data/input_raw \
  --out data/cleaned \
  --do_rembg \
  --do_facecrop
```
Lo script applica remove.bg, ritaglia automaticamente il volto (InsightFace) e salva i file puliti.

### 2. Storyboard e copy con OpenRouter
Genera storyboard, script e caption seed a partire dal prompt bank YAML:
```bash
export OPENROUTER_API_KEY="sk-or-..."
python3 scripts/openrouter_text.py \
  --prompt_bank scripts/prompt_bank.yaml \
  --model meta-llama/llama-3.1-70b-instruct \
  --out data/text/storyboard.json
```
Il risultato Ã¨ un JSON strutturato con scene, dialoghi e caption per guidare i passi successivi.

### 3. Generazione batch di immagini
Crea batch coerenti con le scene e i controlli creativi:
```bash
python3 scripts/openrouter_images.py \
  --prompt_bank scripts/prompt_bank.yaml \
  --model sdxl \
  --out data/synth_openrouter \
  --per_scene 12 \
  --size 1024x1024
```
`--model` accetta sia l'ID completo OpenRouter sia i seguenti alias pronti all'uso:

> Consulta anche [README_OPENROUTER.md](README_OPENROUTER.md) per il catalogo completo degli alias e le tariffe aggiornate.

| Alias | ID completo | Scheda OpenRouter |
| ----- | ----------- | ----------------- |
| `sdxl` | `stabilityai/sdxl` | <https://openrouter.ai/models/stabilityai/sdxl> |
| `sdxl-turbo` | `stabilityai/sdxl-turbo` | <https://openrouter.ai/models/stabilityai/sdxl-turbo> |
| `flux` | `black-forest-labs/flux-1.1-pro` | <https://openrouter.ai/models/black-forest-labs/flux-1.1-pro> |
| `flux-dev` | `black-forest-labs/flux-dev` | <https://openrouter.ai/models/black-forest-labs/flux-dev> |
| `playground-v25` | `playgroundai/playground-v2.5` | <https://openrouter.ai/models/playgroundai/playground-v2.5> |
| `sdxl-lightning` | `luma-photon/stable-diffusion-xl-lightning` | <https://openrouter.ai/models/luma-photon/stable-diffusion-xl-lightning> |

Puoi anche fornire un ID non presente nella tabella (ad esempio un modello privato) e verrÃ  usato direttamente.

Il manifest `manifest.json` associa ad ogni immagine scena, pose, outfit, setup luci e prompt.

### 4. Controllo qualitÃ 
Confronta i render con il volto di riferimento e scarta immagini sfocate o non coerenti:
```bash
python3 scripts/qc_face_sim.py \
  --ref data/cleaned \
  --cand data/synth_openrouter \
  --out data/qc_passed \
  --minsim 0.34 \
  --minblur 80
```
Lo script salva un report CSV con similaritÃ  coseno e punteggio di nitidezza.

### 5. Augment e captioning
Amplia il dataset e crea caption descrittive pronte per l'addestramento:
```bash
python3 scripts/augment_and_caption.py \
  --in data/qc_passed \
  --out data/augment \
  --captions data/captions \
  --meta data/synth_openrouter/manifest.json \
  --num_aug 1
```
Ogni immagine originale viene duplicata con trasformazioni leggere (albumentations) e accompagnata dalla relativa caption `.txt`.

## Gestione dei checkpoint base
Copia uno o piÃ¹ checkpoint SDXL (o modelli compatibili) in `ai_influencer/models/base/` mantenendo l'estensione `.safetensors`:
```bash
cp ~/Downloads/sdxl_base_1.0.safetensors ai_influencer/models/base/sdxl.safetensors
cp ~/models/dreamshaperXL10.safetensors ai_influencer/models/base/dreamshaper_xl.safetensors
```
Lo script `train_lora.sh` utilizza per default `/workspace/models/base/sdxl.safetensors`, ma puoi sostituire il percorso con il flag `--base-model` oppure impostando la variabile d'ambiente `BASE_MODEL`.

### 6. Training LoRA
Dal container `kohya_local` avvia lo script di training scegliendo il modello base desiderato:
```bash
docker exec -it kohya_local bash -lc "bash /workspace/scripts/train_lora.sh --base-model /workspace/models/base/dreamshaper_xl.safetensors"
```
In alternativa esporta la variabile d'ambiente prima dell'esecuzione:
```bash
docker exec -it kohya_local bash -lc "BASE_MODEL=/workspace/models/base/dreamshaper_xl.safetensors bash /workspace/scripts/train_lora.sh"
```
Se non specifichi nulla verrÃ  usato `/workspace/models/base/sdxl.safetensors`. Il comando richiama `accelerate` per eseguire `sd-scripts/train_network.py` con risoluzione 1024Â², salvando gli output in `models/lora/`.

> ðŸ’¡ Smoke test rapido: esegui `bash /workspace/scripts/train_lora.sh --base-model /workspace/models/base/sdxl.safetensors` e verifica nei log la riga `[train_lora] Modello base selezionato: ...` per assicurarti che il parametro venga propagato correttamente.

## Control Hub web
Il servizio `ai_influencer_webapp` espone un pannello su [http://localhost:8000](http://localhost:8000) per:
- consultare i modelli OpenRouter filtrabili per capacitÃ  (testo/immagine/video);
- inviare prompt testuali, visualizzare immagini inline (base64) o scaricare asset remoti;
- lanciare generazioni video e ottenere URL/base64 pronti all'uso;
- simulare la raccolta di insight su un influencer (profilo, metriche, top media) attraverso l'endpoint `/api/influencer`.

La webapp Ã¨ implementata con FastAPI (`ai_influencer/webapp/main.py`) e utilizza `ai_influencer/webapp/openrouter.py` come client asincrono con caching dei modelli e gestione errori.

## Struttura delle cartelle dati
```
ai_influencer/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input_raw/        # immagini sorgente
â”‚   â”œâ”€â”€ cleaned/          # output di prepare_dataset.py
â”‚   â”œâ”€â”€ synth_openrouter/ # batch generati (piÃ¹ manifest.json)
â”‚   â”œâ”€â”€ qc_passed/        # render validati dal QC
â”‚   â”œâ”€â”€ augment/          # dataset finale per il training
â”‚   â””â”€â”€ captions/         # caption .txt allineate alle immagini
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ base/             # modelli base SDXL (piÃ¹ checkpoint .safetensors)
â”‚   â””â”€â”€ lora/             # checkpoint LoRA addestrati
â””â”€â”€ workflows/
    â””â”€â”€ comfyui/          # workflow personalizzati ComfyUI
```

- **GUI desktop** (`scripts/gui_app.py`): fornisce una finestra Tkinter con wizard per API key, preparazione dataset, generazione testo/immagini, QC e augment. Ogni pulsante invoca gli script CLI corrispondenti mostrando i log in tempo reale.
- **Workflow n8n** (`n8n/flow.json`): definisce un webhook che esegue sequenzialmente `prepare_dataset.py`, `openrouter_batch.py` e step collegati all'interno del container Docker; il nodo finale "Train LoRA" accetta un campo JSON `base_model` per scegliere il checkpoint da passare allo script.
- **Script PowerShell** (`scripts/start_machine.ps1`, `scripts/stop_machine.ps1`): facilitano l'avvio/arresto dei container su Windows.

## Test e sviluppo
- Installa le dipendenze di sviluppo:
  ```bash
  pip install -r requirements-dev.txt
  ```
- Esegui la suite:
  ```bash
  pytest
  ```
  I test validano il client OpenRouter (cache, gestione errori, payload chunked) e l'endpoint `/api/influencer` della webapp.

Per modifiche al Control Hub puoi utilizzare l'ambiente Docker `webapp` oppure avviare FastAPI in locale:
```bash
uvicorn ai_influencer.webapp.main:app --reload
```
Assicurati di esportare `OPENROUTER_API_KEY` e, se necessario, `OPENROUTER_APP_TITLE`/`OPENROUTER_APP_URL` per personalizzare gli header verso OpenRouter.

## Documentazione aggiuntiva e licenza
- `ai_influencer/README.md` â€“ manuale operativo dettagliato della pipeline.
- Cartella root â€“ include guide PDF/Docx per ambienti Windows/WSL e configurazioni Docker.
- `ai_influencer/CONTRIBUTING.md`, `CODE_OF_CONDUCT.md`, `SECURITY.md` â€“ linee guida comunitarie.
- Licenza: vedere `ai_influencer/LICENSE`.
